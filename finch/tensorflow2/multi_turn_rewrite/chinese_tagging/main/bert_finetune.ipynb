{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_finetune.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6LBlfq5fiNOW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595998983606,"user_tz":-480,"elapsed":1572,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"e16ecd24-3f49-4456-8814-a8b45ac70d38"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow2/multi_turn_rewrite/chinese_tagging/main')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jExLuIUKYEOT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":392},"executionInfo":{"status":"ok","timestamp":1595998993622,"user_tz":-480,"elapsed":10514,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"d816104e-faa1-45a5-d292-d9d59f851f03"},"source":["%tensorflow_version 2.x\n","!pip install transformers\n","!pip install tensorflow_addons"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow_addons) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RdZa_821Vxmt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"ok","timestamp":1595998999955,"user_tz":-480,"elapsed":15523,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"85ce67e3-a896-43ee-ed81-6bca0f8ddfda"},"source":["from pathlib import Path\n","from sklearn.metrics import accuracy_score\n","from transformers import BertTokenizer, TFBertModel\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import numpy as np\n","import pprint\n","import logging\n","import time\n","\n","print(\"TensorFlow Version\", tf.__version__)\n","print('GPU Enabled:', tf.test.is_gpu_available())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow Version 2.2.0\n","WARNING:tensorflow:From <ipython-input-3-d5d0a65a0e7c>:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n","GPU Enabled: True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Pb9w2iTY2l3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595998999969,"user_tz":-480,"elapsed":14196,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["def get_vocab(f_path):\n","  word2idx = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip('\\n')\n","      word2idx[line] = i\n","  return word2idx"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUll1VH0ns2G","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595998999972,"user_tz":-480,"elapsed":13208,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["params = {\n","  'pretrain_path': 'bert-base-chinese',\n","  'train_path': ['../data/train_pos_tag.txt'],\n","  'test_path': ['../data/test_pos_tag.txt'],\n","  'vocab_path': '../vocab/char.txt',\n","  'batch_size': 16,\n","  'clip_norm': 5.,\n","  'buffer_size': 18986,\n","  'init_lr': 1e-5,\n","  'max_lr': 4e-5,\n","  'n_epochs': 16,\n","}\n","\n","tokenizer = BertTokenizer.from_pretrained(params['pretrain_path'],\n","                                          lowercase = True,\n","                                          add_special_tokens = True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"GEgucHP9iPm1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595998999978,"user_tz":-480,"elapsed":12021,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["def data_generator(f_paths, params):\n","  for f_path in f_paths:\n","    with open(f_path) as f:\n","      print('Reading', f_path)\n","      for line in f:\n","        line = line.rstrip()\n","        h1, h2, q, a, t1, t2 = line.split('\\t')\n","        h1, h2, q = list(h1), list(h2), list(q)\n","        text = ['[CLS]'] + h1 + ['[SEP]'] + h2 + ['[SEP]'] + q + ['[SEP]']\n","        seg = [0] + [0] * len(h1) + [0] + [0] * len(h2) + [0] + [1] * len(q) + [1]\n","        t1 = [int(t) for t in t1]\n","        t2 = [int(t) for t in t2]\n","        label = [0] + t1 + [0] + t2 + [0] + [0] * len(q) + [0]\n","        text = tokenizer.convert_tokens_to_ids(text)\n","        yield (text, seg), label\n","\n","\n","def dataset(is_training, params):\n","  _shapes = (([None], [None]), [None])\n","  _types = ((tf.int32, tf.int32), tf.int32)\n","  _pads = ((0, 0), 0)\n","  \n","  if is_training:\n","    ds = tf.data.Dataset.from_generator(\n","      lambda: data_generator(params['train_path'], params),\n","      output_shapes = _shapes,\n","      output_types = _types,)\n","    ds = ds.shuffle(params['buffer_size'])\n","    ds = ds.padded_batch(params['batch_size'], _shapes, _pads)\n","    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n","  else:\n","    ds = tf.data.Dataset.from_generator(\n","      lambda: data_generator(params['test_path'], params),\n","      output_shapes = _shapes,\n","      output_types = _types,)\n","    ds = ds.padded_batch(params['batch_size'], _shapes, _pads)\n","    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n","  \n","  return ds"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vplgns5KIQC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1595999001816,"user_tz":-480,"elapsed":1811,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"8da23d4a-6698-4fb0-b298-d79875fa01d5"},"source":["(text, seg), label = next(data_generator(params['train_path'], params))\n","print(text)\n","print(seg)\n","print(label)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Reading ../data/train_pos_tag.txt\n","[101, 5543, 5314, 2769, 5041, 1399, 1408, 102, 1139, 683, 6782, 1086, 6379, 102, 2769, 4385, 1762, 2218, 6206, 102]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n","[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zZFQF5599jWZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595999001819,"user_tz":-480,"elapsed":1794,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["class BertFinetune(tf.keras.Model):\n","  def __init__(self, params):\n","    super(BertFinetune, self).__init__()\n","    self.bert = TFBertModel.from_pretrained(params['pretrain_path'],\n","                                            trainable = True)\n","    self.drop_1 = tf.keras.layers.Dropout(.1)\n","    self.fc = tf.keras.layers.Dense(300, tf.nn.swish, name='down_stream/fc')\n","    self.drop_2 = tf.keras.layers.Dropout(.1)\n","    self.out = tf.keras.layers.Dense(1, name='down_stream/out')\n","\n","  def call(self, bert_inputs, training):\n","    bert_inputs = [tf.cast(inp, tf.int32) for inp in bert_inputs]\n","    x = self.bert(bert_inputs, training=training)[0]\n","    x = self.drop_1(x, training=training)\n","    x = self.fc(x)\n","    x = self.drop_2(x, training=training)\n","    x = self.out(x)\n","    x = tf.squeeze(x, -1)\n","    return x"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJhhas0QciEc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595999001827,"user_tz":-480,"elapsed":1786,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["def unit_test(model):\n","  h1 = '成都房价是多少'\n","  h2 = '不买就后悔了成都房价还有上涨空间'\n","  q = '买不起'\n","  text_ = ['[CLS]'] + list(h1) + ['[SEP]'] + list(h2) + ['[SEP]'] + list(q) + ['[SEP]']\n","  text = tf.convert_to_tensor([tokenizer.convert_tokens_to_ids(text_)])\n","  seg = tf.convert_to_tensor([[0] + [0] * len(h1) + [0] + [0] * len(h2) + [0] + [1] * len(q) + [1]])\n","\n","  logits = model([text, tf.sign(text), seg], training=False)\n","  scores = tf.sigmoid(logits)\n","  scores = tf.cast(tf.math.greater_equal(logits, .5), tf.int32)\n","  print('-'*12)\n","  print('unit test')\n","  print('Query:')\n","  print(' '.join(text_))\n","  print('Retrieved:')\n","  str_out = []\n","  for i, val in enumerate(scores[0].numpy()):\n","    if val == 1:\n","      str_out += [text_[i]]\n","  print(' '.join(str_out))\n","  print('-'*12)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"hot1C3r3QvyD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596005814287,"user_tz":-480,"elapsed":6814231,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"0ac79dea-b6bd-48b7-c360-f8ca94f64f77"},"source":["model = BertFinetune(params)\n","model.build([[None, None], [None, None], [None, None]])\n","pprint.pprint([(v.name, v.shape) for v in model.trainable_variables])\n","\n","step_size = 4 * params['buffer_size'] // params['batch_size']\n","decay_lr = tfa.optimizers.Triangular2CyclicalLearningRate(\n","  initial_learning_rate = params['init_lr'],\n","  maximal_learning_rate = params['max_lr'],\n","  step_size = step_size,)\n","optim = tf.optimizers.Adam(params['init_lr'])\n","global_step = 0\n","\n","best_em = .0\n","\n","t0 = time.time()\n","logger = logging.getLogger('tensorflow')\n","logger.setLevel(logging.INFO)\n","\n","unit_test(model)\n","\n","for _ in range(params['n_epochs']):\n","  # TRAINING\n","  for ((text, seg), labels) in dataset(is_training=True, params=params):\n","    with tf.GradientTape() as tape:\n","      masks = tf.sign(text)\n","      logits = model([text, masks, seg], training=True)\n","\n","      labels = tf.cast(labels, tf.float32)\n","      masks = tf.cast(masks, tf.float32)\n","      loss = tf.nn.weighted_cross_entropy_with_logits(labels=labels, logits=logits, pos_weight=2.)\n","      loss = tf.reduce_sum(loss * masks) / tf.reduce_sum(masks)\n","      \n","    optim.lr.assign(decay_lr(global_step))\n","    train_vars = [v for v in model.trainable_variables if v.name != 'tf_bert_model/bert/pooler/dense/kernel:0' and v.name != 'tf_bert_model/bert/pooler/dense/bias:0']\n","    grads = tape.gradient(loss, train_vars)\n","    grads, _ = tf.clip_by_global_norm(grads, params['clip_norm'])\n","    optim.apply_gradients(zip(grads, train_vars))\n","    \n","    if global_step % 100 == 0:\n","      logger.info(\"Step {} | Loss: {:.4f} | Spent: {:.1f} secs | LR: {:.6f}\".format(\n","          global_step, loss.numpy().item(), time.time()-t0, optim.lr.numpy().item()))\n","      t0 = time.time()\n","    global_step += 1\n","  \n","  # EVALUATION\n","  unit_test(model)\n","\n","  l = []\n","  p = []\n","  em = []\n","  for ((text, seg), labels) in dataset(is_training=False, params=params):\n","    logits = model([text, tf.sign(text), seg], training=False)\n","    scores = tf.sigmoid(logits)\n","    scores = tf.cast(tf.math.greater_equal(logits, .5), tf.int32).numpy()\n","    labels = tf.cast(labels, tf.float32).numpy()\n","    l += labels.flatten().tolist()\n","    p += scores.flatten().tolist()\n","    em += [np.array_equal(score, label) for score, label in zip(scores, labels)]\n","  \n","  assert len(l) == len(p)\n","  recall = accuracy_score(l, p, sample_weight=l)\n","  precision = accuracy_score(l, p, sample_weight=p)\n","  em = np.asarray(em).mean()\n","\n","  logger.info(\"Recall: {:.3f} | Precision: {:.3f} | EM: {:.3f}\".format(recall, precision, em))\n","\n","  if em > best_em:\n","    best_em = em\n","  logger.info(\"Best EM: {:.3f}\".format(best_em))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the model checkpoint at bert-base-chinese.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["[('tf_bert_model/bert/embeddings/word_embeddings/weight:0',\n","  TensorShape([21128, 768])),\n"," ('tf_bert_model/bert/embeddings/position_embeddings/embeddings:0',\n","  TensorShape([512, 768])),\n"," ('tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0',\n","  TensorShape([2, 768])),\n"," ('tf_bert_model/bert/embeddings/LayerNorm/gamma:0', TensorShape([768])),\n"," ('tf_bert_model/bert/embeddings/LayerNorm/beta:0', TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/pooler/dense/kernel:0', TensorShape([768, 768])),\n"," ('tf_bert_model/bert/pooler/dense/bias:0', TensorShape([768])),\n"," ('down_stream/fc/kernel:0', TensorShape([768, 300])),\n"," ('down_stream/fc/bias:0', TensorShape([300])),\n"," ('down_stream/out/kernel:0', TensorShape([300, 1])),\n"," ('down_stream/out/bias:0', TensorShape([1]))]\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","[CLS] 少 [SEP] 不 后 房 上 涨 间 [SEP] 买 起 [SEP]\n","------------\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 0 | Loss: 1.0461 | Spent: 5.1 secs | LR: 0.000010\n","INFO:tensorflow:Step 100 | Loss: 0.2660 | Spent: 35.4 secs | LR: 0.000011\n","INFO:tensorflow:Step 200 | Loss: 0.2083 | Spent: 35.0 secs | LR: 0.000011\n","INFO:tensorflow:Step 300 | Loss: 0.1681 | Spent: 35.1 secs | LR: 0.000012\n","INFO:tensorflow:Step 400 | Loss: 0.1945 | Spent: 35.4 secs | LR: 0.000013\n","INFO:tensorflow:Step 500 | Loss: 0.1791 | Spent: 34.9 secs | LR: 0.000013\n","INFO:tensorflow:Step 600 | Loss: 0.2282 | Spent: 35.1 secs | LR: 0.000014\n","INFO:tensorflow:Step 700 | Loss: 0.2103 | Spent: 34.9 secs | LR: 0.000014\n","INFO:tensorflow:Step 800 | Loss: 0.1381 | Spent: 35.5 secs | LR: 0.000015\n","INFO:tensorflow:Step 900 | Loss: 0.1753 | Spent: 35.2 secs | LR: 0.000016\n","INFO:tensorflow:Step 1000 | Loss: 0.2120 | Spent: 35.3 secs | LR: 0.000016\n","INFO:tensorflow:Step 1100 | Loss: 0.1053 | Spent: 35.0 secs | LR: 0.000017\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 价 成 都 房\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.909 | Precision: 0.904 | EM: 0.658\n","INFO:tensorflow:Best EM: 0.658\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 1200 | Loss: 0.0536 | Spent: 47.7 secs | LR: 0.000018\n","INFO:tensorflow:Step 1300 | Loss: 0.1567 | Spent: 35.3 secs | LR: 0.000018\n","INFO:tensorflow:Step 1400 | Loss: 0.0591 | Spent: 35.5 secs | LR: 0.000019\n","INFO:tensorflow:Step 1500 | Loss: 0.1036 | Spent: 35.4 secs | LR: 0.000019\n","INFO:tensorflow:Step 1600 | Loss: 0.1539 | Spent: 35.1 secs | LR: 0.000020\n","INFO:tensorflow:Step 1700 | Loss: 0.1233 | Spent: 35.0 secs | LR: 0.000021\n","INFO:tensorflow:Step 1800 | Loss: 0.1607 | Spent: 35.1 secs | LR: 0.000021\n","INFO:tensorflow:Step 1900 | Loss: 0.2508 | Spent: 34.9 secs | LR: 0.000022\n","INFO:tensorflow:Step 2000 | Loss: 0.1191 | Spent: 35.2 secs | LR: 0.000023\n","INFO:tensorflow:Step 2100 | Loss: 0.1144 | Spent: 35.0 secs | LR: 0.000023\n","INFO:tensorflow:Step 2200 | Loss: 0.0714 | Spent: 35.7 secs | LR: 0.000024\n","INFO:tensorflow:Step 2300 | Loss: 0.1024 | Spent: 34.8 secs | LR: 0.000025\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 价 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.929 | Precision: 0.884 | EM: 0.673\n","INFO:tensorflow:Best EM: 0.673\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 2400 | Loss: 0.0707 | Spent: 47.5 secs | LR: 0.000025\n","INFO:tensorflow:Step 2500 | Loss: 0.0443 | Spent: 35.2 secs | LR: 0.000026\n","INFO:tensorflow:Step 2600 | Loss: 0.0305 | Spent: 35.4 secs | LR: 0.000026\n","INFO:tensorflow:Step 2700 | Loss: 0.1026 | Spent: 34.8 secs | LR: 0.000027\n","INFO:tensorflow:Step 2800 | Loss: 0.0356 | Spent: 35.2 secs | LR: 0.000028\n","INFO:tensorflow:Step 2900 | Loss: 0.0589 | Spent: 35.3 secs | LR: 0.000028\n","INFO:tensorflow:Step 3000 | Loss: 0.0786 | Spent: 34.9 secs | LR: 0.000029\n","INFO:tensorflow:Step 3100 | Loss: 0.0259 | Spent: 35.0 secs | LR: 0.000030\n","INFO:tensorflow:Step 3200 | Loss: 0.0575 | Spent: 35.3 secs | LR: 0.000030\n","INFO:tensorflow:Step 3300 | Loss: 0.1560 | Spent: 35.2 secs | LR: 0.000031\n","INFO:tensorflow:Step 3400 | Loss: 0.1220 | Spent: 35.1 secs | LR: 0.000031\n","INFO:tensorflow:Step 3500 | Loss: 0.1061 | Spent: 34.9 secs | LR: 0.000032\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 价 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.940 | Precision: 0.871 | EM: 0.677\n","INFO:tensorflow:Best EM: 0.677\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 3600 | Loss: 0.1274 | Spent: 47.9 secs | LR: 0.000033\n","INFO:tensorflow:Step 3700 | Loss: 0.0640 | Spent: 35.3 secs | LR: 0.000033\n","INFO:tensorflow:Step 3800 | Loss: 0.0456 | Spent: 35.0 secs | LR: 0.000034\n","INFO:tensorflow:Step 3900 | Loss: 0.0316 | Spent: 35.1 secs | LR: 0.000035\n","INFO:tensorflow:Step 4000 | Loss: 0.0540 | Spent: 35.1 secs | LR: 0.000035\n","INFO:tensorflow:Step 4100 | Loss: 0.0424 | Spent: 34.9 secs | LR: 0.000036\n","INFO:tensorflow:Step 4200 | Loss: 0.0510 | Spent: 35.1 secs | LR: 0.000037\n","INFO:tensorflow:Step 4300 | Loss: 0.0462 | Spent: 34.6 secs | LR: 0.000037\n","INFO:tensorflow:Step 4400 | Loss: 0.0344 | Spent: 34.7 secs | LR: 0.000038\n","INFO:tensorflow:Step 4500 | Loss: 0.0443 | Spent: 34.9 secs | LR: 0.000038\n","INFO:tensorflow:Step 4600 | Loss: 0.1349 | Spent: 34.9 secs | LR: 0.000039\n","INFO:tensorflow:Step 4700 | Loss: 0.0690 | Spent: 34.3 secs | LR: 0.000040\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 成 都 房\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.928 | Precision: 0.801 | EM: 0.660\n","INFO:tensorflow:Best EM: 0.677\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 4800 | Loss: 0.0224 | Spent: 47.6 secs | LR: 0.000040\n","INFO:tensorflow:Step 4900 | Loss: 0.0710 | Spent: 34.7 secs | LR: 0.000039\n","INFO:tensorflow:Step 5000 | Loss: 0.0103 | Spent: 34.4 secs | LR: 0.000038\n","INFO:tensorflow:Step 5100 | Loss: 0.0375 | Spent: 34.9 secs | LR: 0.000038\n","INFO:tensorflow:Step 5200 | Loss: 0.0287 | Spent: 34.7 secs | LR: 0.000037\n","INFO:tensorflow:Step 5300 | Loss: 0.0475 | Spent: 34.7 secs | LR: 0.000036\n","INFO:tensorflow:Step 5400 | Loss: 0.0483 | Spent: 34.6 secs | LR: 0.000036\n","INFO:tensorflow:Step 5500 | Loss: 0.0699 | Spent: 35.4 secs | LR: 0.000035\n","INFO:tensorflow:Step 5600 | Loss: 0.0370 | Spent: 34.5 secs | LR: 0.000035\n","INFO:tensorflow:Step 5700 | Loss: 0.0332 | Spent: 35.0 secs | LR: 0.000034\n","INFO:tensorflow:Step 5800 | Loss: 0.0264 | Spent: 35.0 secs | LR: 0.000033\n","INFO:tensorflow:Step 5900 | Loss: 0.0367 | Spent: 34.9 secs | LR: 0.000033\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 成 都 房\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.931 | Precision: 0.872 | EM: 0.696\n","INFO:tensorflow:Best EM: 0.696\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 6000 | Loss: 0.0243 | Spent: 47.2 secs | LR: 0.000032\n","INFO:tensorflow:Step 6100 | Loss: 0.0340 | Spent: 35.2 secs | LR: 0.000031\n","INFO:tensorflow:Step 6200 | Loss: 0.0268 | Spent: 34.6 secs | LR: 0.000031\n","INFO:tensorflow:Step 6300 | Loss: 0.0201 | Spent: 34.9 secs | LR: 0.000030\n","INFO:tensorflow:Step 6400 | Loss: 0.0046 | Spent: 35.3 secs | LR: 0.000030\n","INFO:tensorflow:Step 6500 | Loss: 0.0044 | Spent: 35.1 secs | LR: 0.000029\n","INFO:tensorflow:Step 6600 | Loss: 0.0362 | Spent: 34.8 secs | LR: 0.000028\n","INFO:tensorflow:Step 6700 | Loss: 0.0350 | Spent: 34.6 secs | LR: 0.000028\n","INFO:tensorflow:Step 6800 | Loss: 0.0305 | Spent: 34.9 secs | LR: 0.000027\n","INFO:tensorflow:Step 6900 | Loss: 0.0775 | Spent: 34.9 secs | LR: 0.000026\n","INFO:tensorflow:Step 7000 | Loss: 0.0152 | Spent: 35.1 secs | LR: 0.000026\n","INFO:tensorflow:Step 7100 | Loss: 0.0154 | Spent: 34.8 secs | LR: 0.000025\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 价 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.936 | Precision: 0.801 | EM: 0.665\n","INFO:tensorflow:Best EM: 0.696\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 7200 | Loss: 0.0059 | Spent: 48.0 secs | LR: 0.000024\n","INFO:tensorflow:Step 7300 | Loss: 0.0128 | Spent: 34.8 secs | LR: 0.000024\n","INFO:tensorflow:Step 7400 | Loss: 0.0420 | Spent: 35.0 secs | LR: 0.000023\n","INFO:tensorflow:Step 7500 | Loss: 0.0067 | Spent: 34.9 secs | LR: 0.000023\n","INFO:tensorflow:Step 7600 | Loss: 0.0084 | Spent: 34.8 secs | LR: 0.000022\n","INFO:tensorflow:Step 7700 | Loss: 0.0054 | Spent: 34.6 secs | LR: 0.000021\n","INFO:tensorflow:Step 7800 | Loss: 0.0034 | Spent: 35.0 secs | LR: 0.000021\n","INFO:tensorflow:Step 7900 | Loss: 0.0191 | Spent: 35.0 secs | LR: 0.000020\n","INFO:tensorflow:Step 8000 | Loss: 0.0067 | Spent: 34.8 secs | LR: 0.000019\n","INFO:tensorflow:Step 8100 | Loss: 0.0132 | Spent: 35.2 secs | LR: 0.000019\n","INFO:tensorflow:Step 8200 | Loss: 0.0146 | Spent: 35.0 secs | LR: 0.000018\n","INFO:tensorflow:Step 8300 | Loss: 0.0119 | Spent: 34.8 secs | LR: 0.000018\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.942 | Precision: 0.844 | EM: 0.698\n","INFO:tensorflow:Best EM: 0.698\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 8400 | Loss: 0.0319 | Spent: 47.5 secs | LR: 0.000017\n","INFO:tensorflow:Step 8500 | Loss: 0.0050 | Spent: 34.7 secs | LR: 0.000016\n","INFO:tensorflow:Step 8600 | Loss: 0.0186 | Spent: 34.6 secs | LR: 0.000016\n","INFO:tensorflow:Step 8700 | Loss: 0.0175 | Spent: 34.8 secs | LR: 0.000015\n","INFO:tensorflow:Step 8800 | Loss: 0.0082 | Spent: 34.5 secs | LR: 0.000014\n","INFO:tensorflow:Step 8900 | Loss: 0.0031 | Spent: 35.2 secs | LR: 0.000014\n","INFO:tensorflow:Step 9000 | Loss: 0.0221 | Spent: 34.6 secs | LR: 0.000013\n","INFO:tensorflow:Step 9100 | Loss: 0.0067 | Spent: 34.9 secs | LR: 0.000012\n","INFO:tensorflow:Step 9200 | Loss: 0.0230 | Spent: 34.9 secs | LR: 0.000012\n","INFO:tensorflow:Step 9300 | Loss: 0.0037 | Spent: 35.1 secs | LR: 0.000011\n","INFO:tensorflow:Step 9400 | Loss: 0.0012 | Spent: 35.0 secs | LR: 0.000011\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.941 | Precision: 0.813 | EM: 0.711\n","INFO:tensorflow:Best EM: 0.711\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 9500 | Loss: 0.0059 | Spent: 47.1 secs | LR: 0.000010\n","INFO:tensorflow:Step 9600 | Loss: 0.0096 | Spent: 34.7 secs | LR: 0.000010\n","INFO:tensorflow:Step 9700 | Loss: 0.0050 | Spent: 34.6 secs | LR: 0.000011\n","INFO:tensorflow:Step 9800 | Loss: 0.0104 | Spent: 35.0 secs | LR: 0.000011\n","INFO:tensorflow:Step 9900 | Loss: 0.0381 | Spent: 34.7 secs | LR: 0.000011\n","INFO:tensorflow:Step 10000 | Loss: 0.0025 | Spent: 34.8 secs | LR: 0.000012\n","INFO:tensorflow:Step 10100 | Loss: 0.0083 | Spent: 35.0 secs | LR: 0.000012\n","INFO:tensorflow:Step 10200 | Loss: 0.0047 | Spent: 34.7 secs | LR: 0.000012\n","INFO:tensorflow:Step 10300 | Loss: 0.0016 | Spent: 34.8 secs | LR: 0.000013\n","INFO:tensorflow:Step 10400 | Loss: 0.0002 | Spent: 35.0 secs | LR: 0.000013\n","INFO:tensorflow:Step 10500 | Loss: 0.0022 | Spent: 34.8 secs | LR: 0.000013\n","INFO:tensorflow:Step 10600 | Loss: 0.0111 | Spent: 35.4 secs | LR: 0.000014\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","房 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.936 | Precision: 0.831 | EM: 0.716\n","INFO:tensorflow:Best EM: 0.716\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 10700 | Loss: 0.0054 | Spent: 47.5 secs | LR: 0.000014\n","INFO:tensorflow:Step 10800 | Loss: 0.0328 | Spent: 35.3 secs | LR: 0.000014\n","INFO:tensorflow:Step 10900 | Loss: 0.0001 | Spent: 34.7 secs | LR: 0.000014\n","INFO:tensorflow:Step 11000 | Loss: 0.0026 | Spent: 34.9 secs | LR: 0.000015\n","INFO:tensorflow:Step 11100 | Loss: 0.0109 | Spent: 34.5 secs | LR: 0.000015\n","INFO:tensorflow:Step 11200 | Loss: 0.0030 | Spent: 34.3 secs | LR: 0.000015\n","INFO:tensorflow:Step 11300 | Loss: 0.0015 | Spent: 34.9 secs | LR: 0.000016\n","INFO:tensorflow:Step 11400 | Loss: 0.0035 | Spent: 35.3 secs | LR: 0.000016\n","INFO:tensorflow:Step 11500 | Loss: 0.0036 | Spent: 35.1 secs | LR: 0.000016\n","INFO:tensorflow:Step 11600 | Loss: 0.0068 | Spent: 34.9 secs | LR: 0.000017\n","INFO:tensorflow:Step 11700 | Loss: 0.0029 | Spent: 34.8 secs | LR: 0.000017\n","INFO:tensorflow:Step 11800 | Loss: 0.0087 | Spent: 34.9 secs | LR: 0.000017\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.937 | Precision: 0.820 | EM: 0.698\n","INFO:tensorflow:Best EM: 0.716\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 11900 | Loss: 0.0111 | Spent: 46.8 secs | LR: 0.000018\n","INFO:tensorflow:Step 12000 | Loss: 0.0043 | Spent: 34.4 secs | LR: 0.000018\n","INFO:tensorflow:Step 12100 | Loss: 0.0026 | Spent: 34.8 secs | LR: 0.000018\n","INFO:tensorflow:Step 12200 | Loss: 0.0061 | Spent: 34.0 secs | LR: 0.000019\n","INFO:tensorflow:Step 12300 | Loss: 0.0182 | Spent: 34.6 secs | LR: 0.000019\n","INFO:tensorflow:Step 12400 | Loss: 0.0145 | Spent: 34.6 secs | LR: 0.000019\n","INFO:tensorflow:Step 12500 | Loss: 0.0065 | Spent: 34.6 secs | LR: 0.000020\n","INFO:tensorflow:Step 12600 | Loss: 0.0029 | Spent: 34.5 secs | LR: 0.000020\n","INFO:tensorflow:Step 12700 | Loss: 0.0153 | Spent: 34.4 secs | LR: 0.000020\n","INFO:tensorflow:Step 12800 | Loss: 0.0035 | Spent: 34.4 secs | LR: 0.000020\n","INFO:tensorflow:Step 12900 | Loss: 0.0005 | Spent: 34.1 secs | LR: 0.000021\n","INFO:tensorflow:Step 13000 | Loss: 0.0038 | Spent: 34.4 secs | LR: 0.000021\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 价 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.949 | Precision: 0.771 | EM: 0.692\n","INFO:tensorflow:Best EM: 0.716\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 13100 | Loss: 0.0025 | Spent: 47.0 secs | LR: 0.000021\n","INFO:tensorflow:Step 13200 | Loss: 0.0462 | Spent: 34.3 secs | LR: 0.000022\n","INFO:tensorflow:Step 13300 | Loss: 0.0187 | Spent: 34.4 secs | LR: 0.000022\n","INFO:tensorflow:Step 13400 | Loss: 0.0075 | Spent: 34.5 secs | LR: 0.000022\n","INFO:tensorflow:Step 13500 | Loss: 0.0015 | Spent: 34.5 secs | LR: 0.000023\n","INFO:tensorflow:Step 13600 | Loss: 0.0034 | Spent: 34.4 secs | LR: 0.000023\n","INFO:tensorflow:Step 13700 | Loss: 0.0016 | Spent: 34.0 secs | LR: 0.000023\n","INFO:tensorflow:Step 13800 | Loss: 0.0011 | Spent: 34.7 secs | LR: 0.000024\n","INFO:tensorflow:Step 13900 | Loss: 0.0044 | Spent: 34.4 secs | LR: 0.000024\n","INFO:tensorflow:Step 14000 | Loss: 0.0029 | Spent: 34.3 secs | LR: 0.000024\n","INFO:tensorflow:Step 14100 | Loss: 0.0038 | Spent: 33.8 secs | LR: 0.000025\n","INFO:tensorflow:Step 14200 | Loss: 0.0063 | Spent: 34.8 secs | LR: 0.000025\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","房 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.949 | Precision: 0.732 | EM: 0.673\n","INFO:tensorflow:Best EM: 0.716\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 14300 | Loss: 0.0055 | Spent: 46.8 secs | LR: 0.000025\n","INFO:tensorflow:Step 14400 | Loss: 0.0081 | Spent: 34.3 secs | LR: 0.000024\n","INFO:tensorflow:Step 14500 | Loss: 0.0080 | Spent: 34.5 secs | LR: 0.000024\n","INFO:tensorflow:Step 14600 | Loss: 0.0013 | Spent: 34.9 secs | LR: 0.000024\n","INFO:tensorflow:Step 14700 | Loss: 0.0021 | Spent: 34.5 secs | LR: 0.000024\n","INFO:tensorflow:Step 14800 | Loss: 0.0014 | Spent: 34.7 secs | LR: 0.000023\n","INFO:tensorflow:Step 14900 | Loss: 0.0642 | Spent: 34.5 secs | LR: 0.000023\n","INFO:tensorflow:Step 15000 | Loss: 0.0025 | Spent: 34.9 secs | LR: 0.000023\n","INFO:tensorflow:Step 15100 | Loss: 0.0064 | Spent: 34.5 secs | LR: 0.000022\n","INFO:tensorflow:Step 15200 | Loss: 0.0336 | Spent: 34.4 secs | LR: 0.000022\n","INFO:tensorflow:Step 15300 | Loss: 0.0143 | Spent: 34.6 secs | LR: 0.000022\n","INFO:tensorflow:Step 15400 | Loss: 0.0676 | Spent: 34.7 secs | LR: 0.000021\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 价 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.937 | Precision: 0.813 | EM: 0.684\n","INFO:tensorflow:Best EM: 0.716\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 15500 | Loss: 0.0007 | Spent: 47.0 secs | LR: 0.000021\n","INFO:tensorflow:Step 15600 | Loss: 0.0194 | Spent: 34.6 secs | LR: 0.000021\n","INFO:tensorflow:Step 15700 | Loss: 0.0061 | Spent: 34.6 secs | LR: 0.000020\n","INFO:tensorflow:Step 15800 | Loss: 0.0033 | Spent: 34.6 secs | LR: 0.000020\n","INFO:tensorflow:Step 15900 | Loss: 0.0116 | Spent: 34.9 secs | LR: 0.000020\n","INFO:tensorflow:Step 16000 | Loss: 0.0062 | Spent: 34.5 secs | LR: 0.000019\n","INFO:tensorflow:Step 16100 | Loss: 0.0033 | Spent: 34.9 secs | LR: 0.000019\n","INFO:tensorflow:Step 16200 | Loss: 0.0003 | Spent: 34.3 secs | LR: 0.000019\n","INFO:tensorflow:Step 16300 | Loss: 0.0036 | Spent: 34.4 secs | LR: 0.000018\n","INFO:tensorflow:Step 16400 | Loss: 0.0048 | Spent: 34.9 secs | LR: 0.000018\n","INFO:tensorflow:Step 16500 | Loss: 0.0019 | Spent: 35.3 secs | LR: 0.000018\n","INFO:tensorflow:Step 16600 | Loss: 0.0022 | Spent: 34.7 secs | LR: 0.000018\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 房 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.943 | Precision: 0.762 | EM: 0.660\n","INFO:tensorflow:Best EM: 0.716\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 16700 | Loss: 0.0039 | Spent: 46.8 secs | LR: 0.000017\n","INFO:tensorflow:Step 16800 | Loss: 0.0003 | Spent: 35.0 secs | LR: 0.000017\n","INFO:tensorflow:Step 16900 | Loss: 0.0184 | Spent: 34.3 secs | LR: 0.000017\n","INFO:tensorflow:Step 17000 | Loss: 0.0002 | Spent: 34.9 secs | LR: 0.000016\n","INFO:tensorflow:Step 17100 | Loss: 0.0019 | Spent: 34.6 secs | LR: 0.000016\n","INFO:tensorflow:Step 17200 | Loss: 0.0128 | Spent: 34.5 secs | LR: 0.000016\n","INFO:tensorflow:Step 17300 | Loss: 0.0000 | Spent: 34.2 secs | LR: 0.000015\n","INFO:tensorflow:Step 17400 | Loss: 0.0004 | Spent: 34.5 secs | LR: 0.000015\n","INFO:tensorflow:Step 17500 | Loss: 0.0028 | Spent: 35.0 secs | LR: 0.000015\n","INFO:tensorflow:Step 17600 | Loss: 0.0020 | Spent: 35.1 secs | LR: 0.000014\n","INFO:tensorflow:Step 17700 | Loss: 0.0043 | Spent: 34.8 secs | LR: 0.000014\n","INFO:tensorflow:Step 17800 | Loss: 0.0013 | Spent: 34.2 secs | LR: 0.000014\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","成 都 房 成 都 房 价\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.939 | Precision: 0.763 | EM: 0.641\n","INFO:tensorflow:Best EM: 0.716\n","Reading ../data/train_pos_tag.txt\n","INFO:tensorflow:Step 17900 | Loss: 0.0045 | Spent: 47.2 secs | LR: 0.000013\n","INFO:tensorflow:Step 18000 | Loss: 0.0102 | Spent: 34.0 secs | LR: 0.000013\n","INFO:tensorflow:Step 18100 | Loss: 0.0016 | Spent: 34.1 secs | LR: 0.000013\n","INFO:tensorflow:Step 18200 | Loss: 0.0001 | Spent: 34.6 secs | LR: 0.000012\n","INFO:tensorflow:Step 18300 | Loss: 0.0038 | Spent: 34.2 secs | LR: 0.000012\n","INFO:tensorflow:Step 18400 | Loss: 0.0000 | Spent: 33.7 secs | LR: 0.000012\n","INFO:tensorflow:Step 18500 | Loss: 0.0002 | Spent: 34.8 secs | LR: 0.000012\n","INFO:tensorflow:Step 18600 | Loss: 0.0032 | Spent: 34.3 secs | LR: 0.000011\n","INFO:tensorflow:Step 18700 | Loss: 0.0004 | Spent: 33.9 secs | LR: 0.000011\n","INFO:tensorflow:Step 18800 | Loss: 0.0214 | Spent: 34.2 secs | LR: 0.000011\n","INFO:tensorflow:Step 18900 | Loss: 0.0009 | Spent: 34.1 secs | LR: 0.000010\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","Retrieved:\n","房 都 房\n","------------\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Recall: 0.935 | Precision: 0.819 | EM: 0.702\n","INFO:tensorflow:Best EM: 0.716\n"],"name":"stdout"}]}]}
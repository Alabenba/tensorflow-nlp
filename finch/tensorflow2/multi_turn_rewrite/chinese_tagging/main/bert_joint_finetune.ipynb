{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_joint_finetune.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6LBlfq5fiNOW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596435114394,"user_tz":-480,"elapsed":1727,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"0b2c323f-6eb4-4b9b-ef3a-3362e0d498e3"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow2/multi_turn_rewrite/chinese_tagging/main')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jExLuIUKYEOT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":392},"executionInfo":{"status":"ok","timestamp":1596435127564,"user_tz":-480,"elapsed":13943,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"ceafd4b5-9552-434a-fcaf-15bd97b58aa9"},"source":["%tensorflow_version 2.x\n","!pip install transformers\n","!pip install tensorflow_addons"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow_addons) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RdZa_821Vxmt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"ok","timestamp":1596435133927,"user_tz":-480,"elapsed":19109,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"503b238d-2900-4b37-e533-f41a9700ebe7"},"source":["from pathlib import Path\n","from sklearn.metrics import accuracy_score\n","from transformers import BertTokenizer, TFBertModel\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import numpy as np\n","import pprint\n","import logging\n","import time\n","\n","print(\"TensorFlow Version\", tf.__version__)\n","print('GPU Enabled:', tf.test.is_gpu_available())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow Version 2.2.0\n","WARNING:tensorflow:From <ipython-input-3-d5d0a65a0e7c>:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n","GPU Enabled: True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Pb9w2iTY2l3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596435136577,"user_tz":-480,"elapsed":2624,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["def get_vocab(f_path):\n","  word2idx = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip('\\n')\n","      word2idx[line] = i\n","  return word2idx"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUll1VH0ns2G","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596435137902,"user_tz":-480,"elapsed":3932,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["params = {\n","  'pretrain_path': 'bert-base-chinese',\n","  'train_paths': ['../data/train_pos_tag.txt', '../data/train_neg_tag.txt'],\n","  'test_paths_1': ['../data/test_pos_tag.txt'],\n","  'test_paths_2': ['../data/test_pos_tag.txt', '../data/test_neg_tag.txt'],\n","  'vocab_path': '../vocab/char.txt',\n","  'batch_size': 16,\n","  'clip_norm': 5.,\n","  'buffer_size': 18986 * 3,\n","  'init_lr': 1e-5,\n","  'max_lr': 4e-5,\n","  'n_epochs': 16,\n","}\n","\n","tokenizer = BertTokenizer.from_pretrained(params['pretrain_path'],\n","                                          lowercase = True,\n","                                          add_special_tokens = True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"GEgucHP9iPm1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596435137907,"user_tz":-480,"elapsed":3915,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["def data_generator(f_paths, params):\n","  for f_path in f_paths:\n","    with open(f_path) as f:\n","      print('Reading', f_path)\n","      for line in f:\n","        line = line.rstrip()\n","        h1, h2, q, intent, t1, t2 = line.split('\\t')\n","        h1, h2, q = list(h1), list(h2), list(q)\n","        text = ['[CLS]'] + h1 + ['[SEP]'] + h2 + ['[SEP]'] + q + ['[SEP]']\n","        seg = [0] + [0] * len(h1) + [0] + [0] * len(h2) + [0] + [1] * len(q) + [1]\n","        t1 = [int(t) for t in t1]\n","        t2 = [int(t) for t in t2]\n","        label = [int(intent)] + t1 + [0] + t2 + [0] + [0] * len(q) + [0]\n","        text = tokenizer.convert_tokens_to_ids(text)\n","        yield (text, seg), label\n","\n","\n","def dataset(paths, is_training, params):\n","  _shapes = (([None], [None]), [None])\n","  _types = ((tf.int32, tf.int32), tf.int32)\n","  _pads = ((0, 0), 0)\n","  \n","  if is_training:\n","    ds = tf.data.Dataset.from_generator(\n","      lambda: data_generator(paths, params),\n","      output_shapes = _shapes,\n","      output_types = _types,)\n","    ds = ds.shuffle(params['buffer_size'])\n","    ds = ds.padded_batch(params['batch_size'], _shapes, _pads)\n","    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n","  else:\n","    ds = tf.data.Dataset.from_generator(\n","      lambda: data_generator(paths, params),\n","      output_shapes = _shapes,\n","      output_types = _types,)\n","    ds = ds.padded_batch(params['batch_size'], _shapes, _pads)\n","    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n","  \n","  return ds"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vplgns5KIQC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1596435137909,"user_tz":-480,"elapsed":3878,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"3bd7f021-5760-42fb-da60-6113572806c9"},"source":["(text, seg), label = next(data_generator(params['train_paths'], params))\n","print(text)\n","print(seg)\n","print(label)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Reading ../data/train_pos_tag.txt\n","[101, 5543, 5314, 2769, 5041, 1399, 1408, 102, 1139, 683, 6782, 1086, 6379, 102, 2769, 4385, 1762, 2218, 6206, 102]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n","[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zZFQF5599jWZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596435137910,"user_tz":-480,"elapsed":3864,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["class BertFinetune(tf.keras.Model):\n","  def __init__(self, params):\n","    super(BertFinetune, self).__init__()\n","    self.bert = TFBertModel.from_pretrained(params['pretrain_path'],\n","                                            trainable = True)\n","    \n","    self.drop_1_labels = tf.keras.layers.Dropout(.1)\n","    self.drop_1_intent = tf.keras.layers.Dropout(.1)\n","\n","    self.fc_labels = tf.keras.layers.Dense(300, tf.nn.swish, name='down_stream/fc_labels')\n","    self.fc_intent = tf.keras.layers.Dense(300, tf.nn.swish, name='down_stream/fc_intent')\n","\n","    self.drop_2_labels = tf.keras.layers.Dropout(.1)\n","    self.drop_2_intent = tf.keras.layers.Dropout(.1)\n","\n","    self.out_labels = tf.keras.layers.Dense(1, name='down_stream/out_labels')\n","    self.out_intent = tf.keras.layers.Dense(3, name='down_stream/out_intent')\n","\n","  def call(self, bert_inputs, training):\n","    bert_inputs = [tf.cast(inp, tf.int32) for inp in bert_inputs]\n","    x = self.bert(bert_inputs, training=training)\n","    x_intent = x[1]\n","    x_labels = x[0][:, 1:, :]\n","\n","    x_intent = self.drop_1_intent(x_intent, training=training)\n","    x_labels = self.drop_1_labels(x_labels, training=training)\n","\n","    x_intent = self.fc_intent(x_intent)\n","    x_labels = self.fc_labels(x_labels)\n","\n","    x_intent = self.drop_2_intent(x_intent, training=training)\n","    x_labels = self.drop_2_labels(x_labels, training=training)\n","\n","    x_intent = self.out_intent(x_intent)\n","    x_labels = self.out_labels(x_labels)\n","\n","    x_labels = tf.squeeze(x_labels, -1)\n","    return x_intent, x_labels"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJhhas0QciEc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596435137916,"user_tz":-480,"elapsed":3864,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["def unit_test(model):\n","  h1 = '成都房价是多少'\n","  h2 = '不买就后悔了成都房价还有上涨空间'\n","  q = '买不起'\n","  text_ = ['[CLS]'] + list(h1) + ['[SEP]'] + list(h2) + ['[SEP]'] + list(q) + ['[SEP]']\n","  text = tf.convert_to_tensor([tokenizer.convert_tokens_to_ids(text_)])\n","  seg = tf.convert_to_tensor([[0] + [0] * len(h1) + [0] + [0] * len(h2) + [0] + [1] * len(q) + [1]])\n","\n","  logits_intent, logits_labels = model([text, tf.sign(text), seg], training=False)\n","  scores_labels = tf.sigmoid(logits_labels)\n","  scores_labels = tf.cast(tf.math.greater_equal(scores_labels, .5), tf.int32)\n","  scores_labels = scores_labels[0].numpy()\n","  scores_intent = tf.argmax(logits_intent, -1)[0].numpy()\n","  print('-'*12)\n","  print('unit test')\n","  print('Query:')\n","  print(' '.join(text_))\n","  print('[CLS]:', scores_intent)\n","  print('Retrieved:')\n","  str_out = []\n","  for i, val in enumerate(scores_labels):\n","    if val == 1:\n","      str_out += [text_[i]]\n","  print(' '.join(str_out))\n","  print('-'*12)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"hot1C3r3QvyD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"77a1329e-a9ed-4ec5-a67c-d57497b2fc76"},"source":["model = BertFinetune(params)\n","model.build([[None, None], [None, None], [None, None]])\n","pprint.pprint([(v.name, v.shape) for v in model.trainable_variables])\n","\n","step_size = 2 * params['buffer_size'] // params['batch_size']\n","decay_lr = tfa.optimizers.Triangular2CyclicalLearningRate(\n","  initial_learning_rate = params['init_lr'],\n","  maximal_learning_rate = params['max_lr'],\n","  step_size = step_size,)\n","optim = tf.optimizers.Adam(params['init_lr'])\n","global_step = 0\n","\n","best_em = .0\n","\n","t0 = time.time()\n","logger = logging.getLogger('tensorflow')\n","logger.setLevel(logging.INFO)\n","\n","unit_test(model)\n","\n","for _ in range(params['n_epochs']):\n","  # TRAINING\n","  for ((text, seg), labels) in dataset(params['train_paths'], is_training=True, params=params):\n","    with tf.GradientTape() as tape:\n","      masks = tf.sign(text)\n","      logits_intent, logits_labels = model([text, masks, seg], training=True)\n","\n","      intents = labels[:, 0]\n","      labels = tf.cast(labels[:, 1:], tf.float32)\n","      masks = tf.cast((masks - seg)[:, 1:], tf.float32)\n","\n","      loss_intent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=intents, logits=logits_intent)\n","      loss_intent = tf.reduce_mean(loss_intent)\n","      loss_labels = tf.nn.weighted_cross_entropy_with_logits(labels=labels, logits=logits_labels, pos_weight=2.)\n","      loss_labels = tf.reduce_sum(loss_labels * masks) / tf.reduce_sum(masks)\n","      loss = loss_intent + loss_labels\n","      \n","    optim.lr.assign(decay_lr(global_step))\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    grads, _ = tf.clip_by_global_norm(grads, params['clip_norm'])\n","    optim.apply_gradients(zip(grads, model.trainable_variables))\n","    \n","    if global_step % 100 == 0:\n","      logger.info(\"Step {} | Loss: {:.4f} | Loss_intent: {:.4f} | Loss_labels: {:.4f} | Spent: {:.1f} secs | LR: {:.6f}\".format(\n","          global_step, loss.numpy().item(), loss_intent.numpy().item(), loss_labels.numpy().item(), time.time()-t0, optim.lr.numpy().item()))\n","      t0 = time.time()\n","    global_step += 1\n","  \n","  # EVALUATION\n","  unit_test(model)\n","\n","  logger.info(\"Evaluation on Positive Testing Examples\")\n","  m = tf.keras.metrics.Accuracy()\n","  l = []\n","  p = []\n","  em = []\n","\n","  for ((text, seg), labels) in dataset(params['test_paths_1'], is_training=False, params=params):\n","    logits_intent, logits_labels = model([text, tf.sign(text), seg], training=False)\n","    scores_labels = tf.sigmoid(logits_labels) * tf.cast(1 - seg[:, 1:], tf.float32)\n","    scores_labels = tf.cast(tf.math.greater_equal(scores_labels, .5), tf.int32).numpy()\n","    labels = labels.numpy()\n","    intents = labels[:, 0]\n","    labels = labels[:, 1:]\n","    l += labels.flatten().tolist()\n","    p += scores_labels.flatten().tolist()\n","    em += [np.array_equal(score, label) for score, label in zip(scores_labels, labels)]\n","    scores_intent = tf.argmax(logits_intent, -1, output_type=tf.dtypes.int32)\n","    m.update_state(y_true=intents, y_pred=scores_intent)\n","  \n","  assert len(l) == len(p)\n","  recall = accuracy_score(l, p, sample_weight=l)\n","  precision = accuracy_score(l, p, sample_weight=p)\n","  em = np.asarray(em).mean()\n","\n","  logger.info(\"Labels:: Recall: {:.3f} | Precision: {:.3f} | EM: {:.3f}\".format(recall, precision, em))\n","  logger.info(\"Intents: Accuracy: {:.3f}\".format(m.result().numpy()))\n","\n","  if em > best_em:\n","    best_em = em\n","  logger.info(\"Best EM: {:.3f}\".format(best_em))\n","\n","  m = tf.keras.metrics.Accuracy()\n","  logger.info(\"Evaluation on Positive + Negative Testing Examples\")\n","  for ((text, seg), labels) in dataset(params['test_paths_2'], is_training=False, params=params):\n","    logits_intent, logits_labels = model([text, tf.sign(text), seg], training=False)\n","    scores_intent = tf.argmax(logits_intent, -1, output_type=tf.dtypes.int32)\n","    labels = labels.numpy()\n","    intents = labels[:, 0]\n","    m.update_state(y_true=intents, y_pred=scores_intent)\n","  logger.info(\"Intent:: Accuracy: {:.3f}\".format(m.result().numpy()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the model checkpoint at bert-base-chinese.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["[('tf_bert_model/bert/embeddings/word_embeddings/weight:0',\n","  TensorShape([21128, 768])),\n"," ('tf_bert_model/bert/embeddings/position_embeddings/embeddings:0',\n","  TensorShape([512, 768])),\n"," ('tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0',\n","  TensorShape([2, 768])),\n"," ('tf_bert_model/bert/embeddings/LayerNorm/gamma:0', TensorShape([768])),\n"," ('tf_bert_model/bert/embeddings/LayerNorm/beta:0', TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0',\n","  TensorShape([768, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0',\n","  TensorShape([768, 3072])),\n"," ('tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0',\n","  TensorShape([3072])),\n"," ('tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0',\n","  TensorShape([3072, 768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0',\n","  TensorShape([768])),\n"," ('tf_bert_model/bert/pooler/dense/kernel:0', TensorShape([768, 768])),\n"," ('tf_bert_model/bert/pooler/dense/bias:0', TensorShape([768])),\n"," ('down_stream/fc_labels/kernel:0', TensorShape([768, 300])),\n"," ('down_stream/fc_labels/bias:0', TensorShape([300])),\n"," ('down_stream/fc_intent/kernel:0', TensorShape([768, 300])),\n"," ('down_stream/fc_intent/bias:0', TensorShape([300])),\n"," ('down_stream/out_labels/kernel:0', TensorShape([300, 1])),\n"," ('down_stream/out_labels/bias:0', TensorShape([1])),\n"," ('down_stream/out_intent/kernel:0', TensorShape([300, 3])),\n"," ('down_stream/out_intent/bias:0', TensorShape([3]))]\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","[CLS]: 0\n","Retrieved:\n","成 房 是 成 房 还 涨 空\n","------------\n","Reading ../data/train_pos_tag.txt\n","Reading ../data/train_neg_tag.txt\n","INFO:tensorflow:Step 0 | Loss: 2.5099 | Loss_intent: 1.6503 | Loss_labels: 0.8596 | Spent: 13.2 secs | LR: 0.000010\n","INFO:tensorflow:Step 100 | Loss: 0.6381 | Loss_intent: 0.2622 | Loss_labels: 0.3760 | Spent: 35.7 secs | LR: 0.000010\n","INFO:tensorflow:Step 200 | Loss: 0.4551 | Loss_intent: 0.1351 | Loss_labels: 0.3200 | Spent: 35.7 secs | LR: 0.000011\n","INFO:tensorflow:Step 300 | Loss: 0.6527 | Loss_intent: 0.2269 | Loss_labels: 0.4258 | Spent: 35.9 secs | LR: 0.000011\n","INFO:tensorflow:Step 400 | Loss: 0.1169 | Loss_intent: 0.0263 | Loss_labels: 0.0906 | Spent: 36.2 secs | LR: 0.000012\n","INFO:tensorflow:Step 500 | Loss: 0.3366 | Loss_intent: 0.0156 | Loss_labels: 0.3210 | Spent: 35.6 secs | LR: 0.000012\n","INFO:tensorflow:Step 600 | Loss: 0.7694 | Loss_intent: 0.4130 | Loss_labels: 0.3563 | Spent: 35.7 secs | LR: 0.000013\n","INFO:tensorflow:Step 700 | Loss: 0.1934 | Loss_intent: 0.0214 | Loss_labels: 0.1720 | Spent: 36.0 secs | LR: 0.000013\n","INFO:tensorflow:Step 800 | Loss: 0.6208 | Loss_intent: 0.2082 | Loss_labels: 0.4126 | Spent: 36.3 secs | LR: 0.000013\n","INFO:tensorflow:Step 900 | Loss: 0.0894 | Loss_intent: 0.0273 | Loss_labels: 0.0621 | Spent: 35.8 secs | LR: 0.000014\n","INFO:tensorflow:Step 1000 | Loss: 0.3297 | Loss_intent: 0.1638 | Loss_labels: 0.1659 | Spent: 35.7 secs | LR: 0.000014\n","INFO:tensorflow:Step 1100 | Loss: 0.1256 | Loss_intent: 0.0090 | Loss_labels: 0.1166 | Spent: 36.5 secs | LR: 0.000015\n","INFO:tensorflow:Step 1200 | Loss: 0.1134 | Loss_intent: 0.0191 | Loss_labels: 0.0942 | Spent: 35.8 secs | LR: 0.000015\n","INFO:tensorflow:Step 1300 | Loss: 0.3255 | Loss_intent: 0.0069 | Loss_labels: 0.3186 | Spent: 35.9 secs | LR: 0.000015\n","INFO:tensorflow:Step 1400 | Loss: 0.2756 | Loss_intent: 0.1323 | Loss_labels: 0.1433 | Spent: 35.7 secs | LR: 0.000016\n","INFO:tensorflow:Step 1500 | Loss: 0.0761 | Loss_intent: 0.0038 | Loss_labels: 0.0722 | Spent: 35.6 secs | LR: 0.000016\n","INFO:tensorflow:Step 1600 | Loss: 0.3859 | Loss_intent: 0.1532 | Loss_labels: 0.2327 | Spent: 35.6 secs | LR: 0.000017\n","INFO:tensorflow:Step 1700 | Loss: 0.4528 | Loss_intent: 0.2668 | Loss_labels: 0.1859 | Spent: 36.6 secs | LR: 0.000017\n","INFO:tensorflow:Step 1800 | Loss: 0.1016 | Loss_intent: 0.0331 | Loss_labels: 0.0685 | Spent: 36.2 secs | LR: 0.000018\n","INFO:tensorflow:Step 1900 | Loss: 0.1575 | Loss_intent: 0.0357 | Loss_labels: 0.1217 | Spent: 36.6 secs | LR: 0.000018\n","INFO:tensorflow:Step 2000 | Loss: 0.3820 | Loss_intent: 0.2348 | Loss_labels: 0.1472 | Spent: 36.5 secs | LR: 0.000018\n","INFO:tensorflow:Step 2100 | Loss: 0.3384 | Loss_intent: 0.1762 | Loss_labels: 0.1622 | Spent: 36.2 secs | LR: 0.000019\n","INFO:tensorflow:Step 2200 | Loss: 0.1910 | Loss_intent: 0.0067 | Loss_labels: 0.1842 | Spent: 36.6 secs | LR: 0.000019\n","INFO:tensorflow:Step 2300 | Loss: 0.8083 | Loss_intent: 0.6192 | Loss_labels: 0.1891 | Spent: 36.5 secs | LR: 0.000020\n","INFO:tensorflow:Step 2400 | Loss: 0.2396 | Loss_intent: 0.0045 | Loss_labels: 0.2350 | Spent: 36.5 secs | LR: 0.000020\n","INFO:tensorflow:Step 2500 | Loss: 0.1951 | Loss_intent: 0.0047 | Loss_labels: 0.1904 | Spent: 36.1 secs | LR: 0.000021\n","INFO:tensorflow:Step 2600 | Loss: 0.1565 | Loss_intent: 0.0026 | Loss_labels: 0.1539 | Spent: 36.1 secs | LR: 0.000021\n","INFO:tensorflow:Step 2700 | Loss: 0.1052 | Loss_intent: 0.0047 | Loss_labels: 0.1005 | Spent: 36.4 secs | LR: 0.000021\n","INFO:tensorflow:Step 2800 | Loss: 0.0852 | Loss_intent: 0.0124 | Loss_labels: 0.0728 | Spent: 36.5 secs | LR: 0.000022\n","INFO:tensorflow:Step 2900 | Loss: 0.3337 | Loss_intent: 0.2531 | Loss_labels: 0.0806 | Spent: 36.0 secs | LR: 0.000022\n","INFO:tensorflow:Step 3000 | Loss: 0.0920 | Loss_intent: 0.0090 | Loss_labels: 0.0831 | Spent: 35.8 secs | LR: 0.000023\n","INFO:tensorflow:Step 3100 | Loss: 0.2695 | Loss_intent: 0.1191 | Loss_labels: 0.1503 | Spent: 36.5 secs | LR: 0.000023\n","INFO:tensorflow:Step 3200 | Loss: 0.3102 | Loss_intent: 0.0836 | Loss_labels: 0.2266 | Spent: 36.1 secs | LR: 0.000023\n","INFO:tensorflow:Step 3300 | Loss: 0.1443 | Loss_intent: 0.0030 | Loss_labels: 0.1413 | Spent: 36.3 secs | LR: 0.000024\n","INFO:tensorflow:Step 3400 | Loss: 0.1041 | Loss_intent: 0.0037 | Loss_labels: 0.1004 | Spent: 36.1 secs | LR: 0.000024\n","INFO:tensorflow:Step 3500 | Loss: 0.1199 | Loss_intent: 0.0131 | Loss_labels: 0.1068 | Spent: 36.1 secs | LR: 0.000025\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","[CLS]: 1\n","Retrieved:\n","[CLS] 成 都 房 了 成 都 房\n","------------\n","INFO:tensorflow:Evaluation on Positive Testing Examples\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Labels:: Recall: 0.858 | Precision: 0.882 | EM: 0.616\n","INFO:tensorflow:Intents: Accuracy: 0.950\n","INFO:tensorflow:Best EM: 0.616\n","INFO:tensorflow:Evaluation on Positive + Negative Testing Examples\n","Reading ../data/test_pos_tag.txt\n","Reading ../data/test_neg_tag.txt\n","INFO:tensorflow:Intent:: Accuracy: 0.976\n","Reading ../data/train_pos_tag.txt\n","Reading ../data/train_neg_tag.txt\n","INFO:tensorflow:Step 3600 | Loss: 0.2586 | Loss_intent: 0.1712 | Loss_labels: 0.0874 | Spent: 80.9 secs | LR: 0.000025\n","INFO:tensorflow:Step 3700 | Loss: 0.4350 | Loss_intent: 0.3210 | Loss_labels: 0.1140 | Spent: 35.6 secs | LR: 0.000026\n","INFO:tensorflow:Step 3800 | Loss: 0.0496 | Loss_intent: 0.0085 | Loss_labels: 0.0411 | Spent: 35.9 secs | LR: 0.000026\n","INFO:tensorflow:Step 3900 | Loss: 0.0468 | Loss_intent: 0.0059 | Loss_labels: 0.0409 | Spent: 35.7 secs | LR: 0.000026\n","INFO:tensorflow:Step 4000 | Loss: 0.2351 | Loss_intent: 0.1249 | Loss_labels: 0.1101 | Spent: 35.5 secs | LR: 0.000027\n","INFO:tensorflow:Step 4100 | Loss: 0.0302 | Loss_intent: 0.0022 | Loss_labels: 0.0281 | Spent: 35.5 secs | LR: 0.000027\n","INFO:tensorflow:Step 4200 | Loss: 0.0279 | Loss_intent: 0.0054 | Loss_labels: 0.0225 | Spent: 35.8 secs | LR: 0.000028\n","INFO:tensorflow:Step 4300 | Loss: 0.1863 | Loss_intent: 0.1151 | Loss_labels: 0.0712 | Spent: 35.8 secs | LR: 0.000028\n","INFO:tensorflow:Step 4400 | Loss: 0.5005 | Loss_intent: 0.3790 | Loss_labels: 0.1215 | Spent: 36.3 secs | LR: 0.000029\n","INFO:tensorflow:Step 4500 | Loss: 0.2237 | Loss_intent: 0.1496 | Loss_labels: 0.0741 | Spent: 35.9 secs | LR: 0.000029\n","INFO:tensorflow:Step 4600 | Loss: 0.6287 | Loss_intent: 0.4549 | Loss_labels: 0.1739 | Spent: 35.5 secs | LR: 0.000029\n","INFO:tensorflow:Step 4700 | Loss: 0.1270 | Loss_intent: 0.0007 | Loss_labels: 0.1263 | Spent: 36.1 secs | LR: 0.000030\n","INFO:tensorflow:Step 4800 | Loss: 0.1599 | Loss_intent: 0.1032 | Loss_labels: 0.0567 | Spent: 35.6 secs | LR: 0.000030\n","INFO:tensorflow:Step 4900 | Loss: 0.0335 | Loss_intent: 0.0006 | Loss_labels: 0.0329 | Spent: 35.5 secs | LR: 0.000031\n","INFO:tensorflow:Step 5000 | Loss: 0.1431 | Loss_intent: 0.0595 | Loss_labels: 0.0836 | Spent: 36.2 secs | LR: 0.000031\n","INFO:tensorflow:Step 5100 | Loss: 0.1733 | Loss_intent: 0.0005 | Loss_labels: 0.1728 | Spent: 35.4 secs | LR: 0.000031\n","INFO:tensorflow:Step 5200 | Loss: 0.1984 | Loss_intent: 0.1429 | Loss_labels: 0.0555 | Spent: 35.9 secs | LR: 0.000032\n","INFO:tensorflow:Step 5300 | Loss: 0.1584 | Loss_intent: 0.0673 | Loss_labels: 0.0911 | Spent: 36.1 secs | LR: 0.000032\n","INFO:tensorflow:Step 5400 | Loss: 0.2640 | Loss_intent: 0.0405 | Loss_labels: 0.2236 | Spent: 36.5 secs | LR: 0.000033\n","INFO:tensorflow:Step 5500 | Loss: 0.0980 | Loss_intent: 0.0207 | Loss_labels: 0.0772 | Spent: 35.7 secs | LR: 0.000033\n","INFO:tensorflow:Step 5600 | Loss: 0.1283 | Loss_intent: 0.0020 | Loss_labels: 0.1263 | Spent: 36.1 secs | LR: 0.000034\n","INFO:tensorflow:Step 5700 | Loss: 0.0289 | Loss_intent: 0.0014 | Loss_labels: 0.0275 | Spent: 35.5 secs | LR: 0.000034\n","INFO:tensorflow:Step 5800 | Loss: 0.0535 | Loss_intent: 0.0017 | Loss_labels: 0.0518 | Spent: 36.6 secs | LR: 0.000034\n","INFO:tensorflow:Step 5900 | Loss: 0.4853 | Loss_intent: 0.3056 | Loss_labels: 0.1797 | Spent: 36.1 secs | LR: 0.000035\n","INFO:tensorflow:Step 6000 | Loss: 0.0750 | Loss_intent: 0.0012 | Loss_labels: 0.0738 | Spent: 35.4 secs | LR: 0.000035\n","INFO:tensorflow:Step 6100 | Loss: 0.2817 | Loss_intent: 0.0734 | Loss_labels: 0.2083 | Spent: 35.5 secs | LR: 0.000036\n","INFO:tensorflow:Step 6200 | Loss: 0.0789 | Loss_intent: 0.0071 | Loss_labels: 0.0717 | Spent: 36.2 secs | LR: 0.000036\n","INFO:tensorflow:Step 6300 | Loss: 0.0849 | Loss_intent: 0.0018 | Loss_labels: 0.0831 | Spent: 35.8 secs | LR: 0.000037\n","INFO:tensorflow:Step 6400 | Loss: 0.1005 | Loss_intent: 0.0118 | Loss_labels: 0.0887 | Spent: 35.3 secs | LR: 0.000037\n","INFO:tensorflow:Step 6500 | Loss: 0.0170 | Loss_intent: 0.0009 | Loss_labels: 0.0161 | Spent: 35.3 secs | LR: 0.000037\n","INFO:tensorflow:Step 6600 | Loss: 0.1730 | Loss_intent: 0.0022 | Loss_labels: 0.1707 | Spent: 35.4 secs | LR: 0.000038\n","INFO:tensorflow:Step 6700 | Loss: 0.1734 | Loss_intent: 0.0550 | Loss_labels: 0.1184 | Spent: 35.7 secs | LR: 0.000038\n","INFO:tensorflow:Step 6800 | Loss: 0.1427 | Loss_intent: 0.0114 | Loss_labels: 0.1313 | Spent: 35.8 secs | LR: 0.000039\n","INFO:tensorflow:Step 6900 | Loss: 0.0284 | Loss_intent: 0.0037 | Loss_labels: 0.0247 | Spent: 35.1 secs | LR: 0.000039\n","INFO:tensorflow:Step 7000 | Loss: 0.1251 | Loss_intent: 0.0080 | Loss_labels: 0.1171 | Spent: 35.9 secs | LR: 0.000039\n","INFO:tensorflow:Step 7100 | Loss: 0.1672 | Loss_intent: 0.0080 | Loss_labels: 0.1592 | Spent: 35.7 secs | LR: 0.000040\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","[CLS]: 1\n","Retrieved:\n","[CLS] 成 都 房 了 成 都 房\n","------------\n","INFO:tensorflow:Evaluation on Positive Testing Examples\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Labels:: Recall: 0.924 | Precision: 0.656 | EM: 0.537\n","INFO:tensorflow:Intents: Accuracy: 0.967\n","INFO:tensorflow:Best EM: 0.616\n","INFO:tensorflow:Evaluation on Positive + Negative Testing Examples\n","Reading ../data/test_pos_tag.txt\n","Reading ../data/test_neg_tag.txt\n","INFO:tensorflow:Intent:: Accuracy: 0.974\n","Reading ../data/train_pos_tag.txt\n","Reading ../data/train_neg_tag.txt\n","INFO:tensorflow:Step 7200 | Loss: 0.0306 | Loss_intent: 0.0043 | Loss_labels: 0.0264 | Spent: 80.2 secs | LR: 0.000040\n","INFO:tensorflow:Step 7300 | Loss: 0.0863 | Loss_intent: 0.0015 | Loss_labels: 0.0848 | Spent: 35.8 secs | LR: 0.000039\n","INFO:tensorflow:Step 7400 | Loss: 0.0553 | Loss_intent: 0.0057 | Loss_labels: 0.0496 | Spent: 35.5 secs | LR: 0.000039\n","INFO:tensorflow:Step 7500 | Loss: 0.0671 | Loss_intent: 0.0018 | Loss_labels: 0.0653 | Spent: 36.4 secs | LR: 0.000038\n","INFO:tensorflow:Step 7600 | Loss: 0.0974 | Loss_intent: 0.0643 | Loss_labels: 0.0331 | Spent: 35.5 secs | LR: 0.000038\n","INFO:tensorflow:Step 7700 | Loss: 0.0435 | Loss_intent: 0.0041 | Loss_labels: 0.0394 | Spent: 36.1 secs | LR: 0.000038\n","INFO:tensorflow:Step 7800 | Loss: 0.2420 | Loss_intent: 0.0003 | Loss_labels: 0.2417 | Spent: 36.5 secs | LR: 0.000037\n","INFO:tensorflow:Step 7900 | Loss: 0.0768 | Loss_intent: 0.0004 | Loss_labels: 0.0763 | Spent: 35.9 secs | LR: 0.000037\n","INFO:tensorflow:Step 8000 | Loss: 0.1359 | Loss_intent: 0.0153 | Loss_labels: 0.1206 | Spent: 36.4 secs | LR: 0.000036\n","INFO:tensorflow:Step 8100 | Loss: 0.0712 | Loss_intent: 0.0014 | Loss_labels: 0.0698 | Spent: 35.9 secs | LR: 0.000036\n","INFO:tensorflow:Step 8200 | Loss: 0.1397 | Loss_intent: 0.0014 | Loss_labels: 0.1383 | Spent: 36.1 secs | LR: 0.000035\n","INFO:tensorflow:Step 8300 | Loss: 0.0254 | Loss_intent: 0.0004 | Loss_labels: 0.0251 | Spent: 36.1 secs | LR: 0.000035\n","INFO:tensorflow:Step 8400 | Loss: 0.0415 | Loss_intent: 0.0011 | Loss_labels: 0.0404 | Spent: 35.6 secs | LR: 0.000035\n","INFO:tensorflow:Step 8500 | Loss: 0.0449 | Loss_intent: 0.0008 | Loss_labels: 0.0441 | Spent: 36.0 secs | LR: 0.000034\n","INFO:tensorflow:Step 8600 | Loss: 0.0436 | Loss_intent: 0.0009 | Loss_labels: 0.0427 | Spent: 36.2 secs | LR: 0.000034\n","INFO:tensorflow:Step 8700 | Loss: 0.1009 | Loss_intent: 0.0050 | Loss_labels: 0.0959 | Spent: 35.9 secs | LR: 0.000033\n","INFO:tensorflow:Step 8800 | Loss: 0.0908 | Loss_intent: 0.0036 | Loss_labels: 0.0871 | Spent: 35.8 secs | LR: 0.000033\n","INFO:tensorflow:Step 8900 | Loss: 0.1411 | Loss_intent: 0.0009 | Loss_labels: 0.1402 | Spent: 36.2 secs | LR: 0.000032\n","INFO:tensorflow:Step 9000 | Loss: 0.1038 | Loss_intent: 0.0013 | Loss_labels: 0.1025 | Spent: 35.4 secs | LR: 0.000032\n","INFO:tensorflow:Step 9100 | Loss: 0.0753 | Loss_intent: 0.0019 | Loss_labels: 0.0734 | Spent: 36.0 secs | LR: 0.000032\n","INFO:tensorflow:Step 9200 | Loss: 0.1409 | Loss_intent: 0.0009 | Loss_labels: 0.1400 | Spent: 35.6 secs | LR: 0.000031\n","INFO:tensorflow:Step 9300 | Loss: 0.0937 | Loss_intent: 0.0023 | Loss_labels: 0.0914 | Spent: 36.0 secs | LR: 0.000031\n","INFO:tensorflow:Step 9400 | Loss: 0.5700 | Loss_intent: 0.3194 | Loss_labels: 0.2505 | Spent: 35.3 secs | LR: 0.000030\n","INFO:tensorflow:Step 9500 | Loss: 0.1006 | Loss_intent: 0.0009 | Loss_labels: 0.0998 | Spent: 35.9 secs | LR: 0.000030\n","INFO:tensorflow:Step 9600 | Loss: 0.0575 | Loss_intent: 0.0019 | Loss_labels: 0.0556 | Spent: 35.9 secs | LR: 0.000030\n","INFO:tensorflow:Step 9700 | Loss: 0.0321 | Loss_intent: 0.0004 | Loss_labels: 0.0316 | Spent: 35.1 secs | LR: 0.000029\n","INFO:tensorflow:Step 9800 | Loss: 0.1513 | Loss_intent: 0.0571 | Loss_labels: 0.0942 | Spent: 35.7 secs | LR: 0.000029\n","INFO:tensorflow:Step 9900 | Loss: 0.0078 | Loss_intent: 0.0010 | Loss_labels: 0.0068 | Spent: 34.9 secs | LR: 0.000028\n","INFO:tensorflow:Step 10000 | Loss: 0.2473 | Loss_intent: 0.1662 | Loss_labels: 0.0811 | Spent: 35.5 secs | LR: 0.000028\n","INFO:tensorflow:Step 10100 | Loss: 0.0621 | Loss_intent: 0.0016 | Loss_labels: 0.0605 | Spent: 35.4 secs | LR: 0.000027\n","INFO:tensorflow:Step 10200 | Loss: 0.0988 | Loss_intent: 0.0007 | Loss_labels: 0.0981 | Spent: 35.7 secs | LR: 0.000027\n","INFO:tensorflow:Step 10300 | Loss: 0.1060 | Loss_intent: 0.0021 | Loss_labels: 0.1039 | Spent: 35.4 secs | LR: 0.000027\n","INFO:tensorflow:Step 10400 | Loss: 0.0906 | Loss_intent: 0.0043 | Loss_labels: 0.0863 | Spent: 36.1 secs | LR: 0.000026\n","INFO:tensorflow:Step 10500 | Loss: 0.0516 | Loss_intent: 0.0058 | Loss_labels: 0.0457 | Spent: 35.4 secs | LR: 0.000026\n","INFO:tensorflow:Step 10600 | Loss: 0.0637 | Loss_intent: 0.0017 | Loss_labels: 0.0620 | Spent: 35.2 secs | LR: 0.000025\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","[CLS]: 1\n","Retrieved:\n","[CLS] 成 都 房 了 成 都 房\n","------------\n","INFO:tensorflow:Evaluation on Positive Testing Examples\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Labels:: Recall: 0.900 | Precision: 0.683 | EM: 0.530\n","INFO:tensorflow:Intents: Accuracy: 0.961\n","INFO:tensorflow:Best EM: 0.616\n","INFO:tensorflow:Evaluation on Positive + Negative Testing Examples\n","Reading ../data/test_pos_tag.txt\n","Reading ../data/test_neg_tag.txt\n","INFO:tensorflow:Intent:: Accuracy: 0.976\n","Reading ../data/train_pos_tag.txt\n","Reading ../data/train_neg_tag.txt\n","INFO:tensorflow:Step 10700 | Loss: 0.2215 | Loss_intent: 0.1263 | Loss_labels: 0.0953 | Spent: 80.1 secs | LR: 0.000025\n","INFO:tensorflow:Step 10800 | Loss: 0.0339 | Loss_intent: 0.0006 | Loss_labels: 0.0334 | Spent: 35.4 secs | LR: 0.000024\n","INFO:tensorflow:Step 10900 | Loss: 0.0581 | Loss_intent: 0.0001 | Loss_labels: 0.0581 | Spent: 36.6 secs | LR: 0.000024\n","INFO:tensorflow:Step 11000 | Loss: 0.0179 | Loss_intent: 0.0007 | Loss_labels: 0.0173 | Spent: 36.8 secs | LR: 0.000024\n","INFO:tensorflow:Step 11100 | Loss: 0.0199 | Loss_intent: 0.0011 | Loss_labels: 0.0188 | Spent: 35.9 secs | LR: 0.000023\n","INFO:tensorflow:Step 11200 | Loss: 0.0415 | Loss_intent: 0.0004 | Loss_labels: 0.0410 | Spent: 35.9 secs | LR: 0.000023\n","INFO:tensorflow:Step 11300 | Loss: 0.0194 | Loss_intent: 0.0003 | Loss_labels: 0.0191 | Spent: 36.2 secs | LR: 0.000022\n","INFO:tensorflow:Step 11400 | Loss: 0.0515 | Loss_intent: 0.0006 | Loss_labels: 0.0508 | Spent: 35.7 secs | LR: 0.000022\n","INFO:tensorflow:Step 11500 | Loss: 0.0388 | Loss_intent: 0.0006 | Loss_labels: 0.0383 | Spent: 35.9 secs | LR: 0.000022\n","INFO:tensorflow:Step 11600 | Loss: 0.0226 | Loss_intent: 0.0007 | Loss_labels: 0.0219 | Spent: 35.9 secs | LR: 0.000021\n","INFO:tensorflow:Step 11700 | Loss: 0.0408 | Loss_intent: 0.0003 | Loss_labels: 0.0406 | Spent: 36.4 secs | LR: 0.000021\n","INFO:tensorflow:Step 11800 | Loss: 0.0500 | Loss_intent: 0.0009 | Loss_labels: 0.0491 | Spent: 36.0 secs | LR: 0.000020\n","INFO:tensorflow:Step 11900 | Loss: 0.0036 | Loss_intent: 0.0002 | Loss_labels: 0.0034 | Spent: 35.6 secs | LR: 0.000020\n","INFO:tensorflow:Step 12000 | Loss: 0.0715 | Loss_intent: 0.0004 | Loss_labels: 0.0710 | Spent: 36.3 secs | LR: 0.000019\n","INFO:tensorflow:Step 12100 | Loss: 0.0140 | Loss_intent: 0.0001 | Loss_labels: 0.0139 | Spent: 36.3 secs | LR: 0.000019\n","INFO:tensorflow:Step 12200 | Loss: 0.0594 | Loss_intent: 0.0003 | Loss_labels: 0.0591 | Spent: 35.9 secs | LR: 0.000019\n","INFO:tensorflow:Step 12300 | Loss: 0.0763 | Loss_intent: 0.0003 | Loss_labels: 0.0760 | Spent: 36.4 secs | LR: 0.000018\n","INFO:tensorflow:Step 12400 | Loss: 0.0234 | Loss_intent: 0.0013 | Loss_labels: 0.0221 | Spent: 36.6 secs | LR: 0.000018\n","INFO:tensorflow:Step 12500 | Loss: 0.0363 | Loss_intent: 0.0004 | Loss_labels: 0.0359 | Spent: 36.4 secs | LR: 0.000017\n","INFO:tensorflow:Step 12600 | Loss: 0.0357 | Loss_intent: 0.0003 | Loss_labels: 0.0354 | Spent: 36.2 secs | LR: 0.000017\n","INFO:tensorflow:Step 12700 | Loss: 0.1010 | Loss_intent: 0.0125 | Loss_labels: 0.0884 | Spent: 36.5 secs | LR: 0.000016\n","INFO:tensorflow:Step 12800 | Loss: 0.0634 | Loss_intent: 0.0001 | Loss_labels: 0.0633 | Spent: 36.8 secs | LR: 0.000016\n","INFO:tensorflow:Step 12900 | Loss: 0.1756 | Loss_intent: 0.1465 | Loss_labels: 0.0290 | Spent: 36.3 secs | LR: 0.000016\n","INFO:tensorflow:Step 13000 | Loss: 0.0047 | Loss_intent: 0.0002 | Loss_labels: 0.0045 | Spent: 36.7 secs | LR: 0.000015\n","INFO:tensorflow:Step 13100 | Loss: 0.1146 | Loss_intent: 0.0049 | Loss_labels: 0.1097 | Spent: 36.6 secs | LR: 0.000015\n","INFO:tensorflow:Step 13200 | Loss: 0.0291 | Loss_intent: 0.0002 | Loss_labels: 0.0289 | Spent: 36.6 secs | LR: 0.000014\n","INFO:tensorflow:Step 13300 | Loss: 0.0085 | Loss_intent: 0.0003 | Loss_labels: 0.0083 | Spent: 36.3 secs | LR: 0.000014\n","INFO:tensorflow:Step 13400 | Loss: 0.0219 | Loss_intent: 0.0017 | Loss_labels: 0.0202 | Spent: 36.3 secs | LR: 0.000014\n","INFO:tensorflow:Step 13500 | Loss: 0.0162 | Loss_intent: 0.0001 | Loss_labels: 0.0161 | Spent: 35.7 secs | LR: 0.000013\n","INFO:tensorflow:Step 13600 | Loss: 0.0114 | Loss_intent: 0.0001 | Loss_labels: 0.0113 | Spent: 36.1 secs | LR: 0.000013\n","INFO:tensorflow:Step 13700 | Loss: 0.0623 | Loss_intent: 0.0004 | Loss_labels: 0.0619 | Spent: 36.5 secs | LR: 0.000012\n","INFO:tensorflow:Step 13800 | Loss: 0.1181 | Loss_intent: 0.0002 | Loss_labels: 0.1179 | Spent: 35.7 secs | LR: 0.000012\n","INFO:tensorflow:Step 13900 | Loss: 0.0200 | Loss_intent: 0.0011 | Loss_labels: 0.0189 | Spent: 35.9 secs | LR: 0.000011\n","INFO:tensorflow:Step 14000 | Loss: 0.0695 | Loss_intent: 0.0002 | Loss_labels: 0.0693 | Spent: 36.0 secs | LR: 0.000011\n","INFO:tensorflow:Step 14100 | Loss: 0.0179 | Loss_intent: 0.0023 | Loss_labels: 0.0156 | Spent: 36.0 secs | LR: 0.000011\n","INFO:tensorflow:Step 14200 | Loss: 0.0245 | Loss_intent: 0.0002 | Loss_labels: 0.0243 | Spent: 36.2 secs | LR: 0.000010\n","------------\n","unit test\n","Query:\n","[CLS] 成 都 房 价 是 多 少 [SEP] 不 买 就 后 悔 了 成 都 房 价 还 有 上 涨 空 间 [SEP] 买 不 起 [SEP]\n","[CLS]: 1\n","Retrieved:\n","[CLS] 成 都 房 了 成 都 房\n","------------\n","INFO:tensorflow:Evaluation on Positive Testing Examples\n","Reading ../data/test_pos_tag.txt\n","INFO:tensorflow:Labels:: Recall: 0.920 | Precision: 0.607 | EM: 0.520\n","INFO:tensorflow:Intents: Accuracy: 0.957\n","INFO:tensorflow:Best EM: 0.616\n","INFO:tensorflow:Evaluation on Positive + Negative Testing Examples\n","Reading ../data/test_pos_tag.txt\n","Reading ../data/test_neg_tag.txt\n","INFO:tensorflow:Intent:: Accuracy: 0.977\n","Reading ../data/train_pos_tag.txt\n","Reading ../data/train_neg_tag.txt\n"],"name":"stdout"}]}]}
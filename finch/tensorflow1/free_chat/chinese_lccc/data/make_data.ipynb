{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"make_data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNjqD48y8C3K7vCuHgN46qi"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"FJPv38giDj65","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597302978334,"user_tz":-480,"elapsed":2282,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"52ad4b9b-f0b8-42fd-fe3e-30039af0a2f4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese_lccc/data')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H5uihnC7Dw65","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597302979522,"user_tz":-480,"elapsed":2362,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["from collections import Counter\n","from pathlib import Path\n","\n","import json\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpsB9ix7DyFE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597303049592,"user_tz":-480,"elapsed":71293,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["with open('LCCC-base.json') as f:\n","  data = json.load(f)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0LS6-KlKGIlW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1597303073435,"user_tz":-480,"elapsed":66970,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"15df06f5-db4c-400f-b656-08fe16eac60d"},"source":["Path('../vocab').mkdir(exist_ok=True)\n","char_counter = Counter()\n","src_lens, tgt_lens = [], []\n","i = 0\n","\n","with open('train.txt', 'w') as f_out:\n","  for line in data['train']:\n","    if i == 2000000:\n","      break\n","    if len(line) < 2:\n","      continue\n","    elif len(line) == 2:\n","      src, tgt = line\n","      src = src.lower().split()\n","      tgt = tgt.lower().split()\n","      char_counter.update(src)\n","      char_counter.update(tgt)\n","      src_lens.append(len(src))\n","      tgt_lens.append(len(tgt))\n","      f_out.write(''.join(src)+'<SEP>'+''.join(tgt)+'\\n')\n","      i += 1\n","    else:\n","      for src, tgt in zip (line, line[1:]):\n","        src = src.lower().split()\n","        tgt = tgt.lower().split()\n","        char_counter.update(src)\n","        char_counter.update(tgt)\n","        src_lens.append(len(src))\n","        tgt_lens.append(len(tgt))\n","        f_out.write(''.join(src)+'<SEP>'+''.join(tgt)+'\\n')\n","        i += 1\n","\n","print('Source Average Length', sum(src_lens)/len(src_lens))\n","print('Target Average Length', sum(tgt_lens)/len(tgt_lens))\n","\n","chars = ['<pad>', '<start>', '<end>'] + [char for char, freq in char_counter.most_common() if freq >= 50]\n","print(len(chars), 'Chars')\n","with open('../vocab/char.txt', 'w') as f:\n","  for c in chars:\n","    f.write(c+'\\n')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Source Average Length 12.8481\n","Target Average Length 11.295644\n","3926 Chars\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nbGn7XO1UGJ0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597303079248,"user_tz":-480,"elapsed":5797,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["with open('LCCC-base_test.json') as f:\n","  data = json.load(f)\n","\n","with open('test.txt', 'w') as f_out:\n","  for line in data:\n","    if len(line) < 2:\n","      continue\n","    elif len(line) == 2:\n","      src, tgt = line\n","      src = src.lower().split()\n","      tgt = tgt.lower().split()\n","      f_out.write(''.join(src)+'<SEP>'+''.join(tgt)+'\\n')\n","    else:\n","      for src, tgt in zip (line, line[1:]):\n","        src = src.split()\n","        tgt = tgt.split()\n","        f_out.write(''.join(src)+'<SEP>'+''.join(tgt)+'\\n')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnCOmSM6YLnP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":410},"executionInfo":{"status":"ok","timestamp":1597303163191,"user_tz":-480,"elapsed":89725,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"e5848021-7565-44e9-e166-b51abce53fe2"},"source":["char2idx = {}\n","with open('../vocab/char.txt') as f:\n","  for i, line in enumerate(f):\n","    line = line.rstrip('\\n')\n","    char2idx[line] = i\n","\n","embedding = np.zeros((len(char2idx)+1, 300)) # + 1 for unknown word\n","\n","with open('../vocab/cc.zh.300.vec') as f:\n","  count = 0\n","  for i, line in enumerate(f):\n","    if i == 0:\n","      continue\n","    if i % 100000 == 0:\n","      print('- At line {}'.format(i))\n","    line = line.rstrip()\n","    sp = line.split(' ')\n","    word, vec = sp[0], sp[1:]\n","    if word in char2idx:\n","      count += 1\n","      embedding[char2idx[word]] = np.asarray(vec, dtype='float32')\n","      \n","print(\"[%d / %d] characters have found pre-trained values\"%(count, len(char2idx)))\n","np.save('../vocab/char.npy', embedding)\n","print('Saved ../vocab/char.npy')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["- At line 100000\n","- At line 200000\n","- At line 300000\n","- At line 400000\n","- At line 500000\n","- At line 600000\n","- At line 700000\n","- At line 800000\n","- At line 900000\n","- At line 1000000\n","- At line 1100000\n","- At line 1200000\n","- At line 1300000\n","- At line 1400000\n","- At line 1500000\n","- At line 1600000\n","- At line 1700000\n","- At line 1800000\n","- At line 1900000\n","- At line 2000000\n","[3844 / 3926] characters have found pre-trained values\n","Saved ../vocab/char.npy\n"],"name":"stdout"}]}]}
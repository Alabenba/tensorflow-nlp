{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformer_export.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOM7YKCl8W9wtoGKjvzaRco"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"nffJUQ0TWw9p","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese_lccc/main')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mIt87oKkX5WV","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","!pip install texar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qq1_wrpX7wv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1597653280940,"user_tz":-480,"elapsed":28402,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"ec3e718b-5be5-4d13-caf1-76f6dab908a7"},"source":["import tensorflow as tf\n","import texar.tf as tx\n","import numpy as np\n","import copy\n","\n","from texar.tf.modules import TransformerEncoder\n","\n","print(\"TensorFlow Version\", tf.__version__)\n","print('GPU Enabled:', tf.test.is_gpu_available())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow Version 1.15.2\n","GPU Enabled: False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iQOti3AUh3D8","colab_type":"code","colab":{}},"source":["def rnn_cell():\n","  def cell_fn():\n","    cell = tf.nn.rnn_cell.LSTMCell(params['rnn_units'],\n","                                  initializer=tf.orthogonal_initializer())\n","    return cell\n","  if params['dec_layers'] > 1:\n","    cells = []\n","    for i in range(params['dec_layers']):\n","      if i == params['dec_layers'] - 1:\n","        cells.append(cell_fn())\n","      else:\n","        cells.append(tf.nn.rnn_cell.ResidualWrapper(cell_fn(), residual_fn=lambda i,o: tf.concat((i,o), -1)))\n","    return tf.nn.rnn_cell.MultiRNNCell(cells)\n","  else:\n","    return cell_fn()\n","\n","  \n","def dec_cell(enc_out, enc_seq_len):\n","  attn = tf.contrib.seq2seq.BahdanauAttention(\n","    num_units = params['rnn_units'],\n","    memory = enc_out,\n","    memory_sequence_length = enc_seq_len)\n","  \n","  return tf.contrib.seq2seq.AttentionWrapper(\n","    cell = rnn_cell(),\n","    attention_mechanism = attn,\n","    attention_layer_size = params['rnn_units'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-vYO_fWJh5QS","colab_type":"code","colab":{}},"source":["class TiedDense(tf.layers.Layer):\n","  def __init__(self, tied_embed, out_dim):\n","    super().__init__()\n","    self.tied_embed = tied_embed\n","    self.out_dim = out_dim\n","  \n","  def build(self, input_shape):\n","    self.bias = self.add_weight(name='bias',\n","                                shape=[self.out_dim],\n","                                trainable=True)\n","    super().build(input_shape)\n","  \n","  def call(self, inputs):\n","    x = tf.matmul(inputs, self.tied_embed, transpose_b=True)\n","    x = tf.nn.bias_add(x, self.bias)\n","    return x\n","  \n","  def compute_output_shape(self, input_shape):\n","    return input_shape[:-1].concatenate(self.out_dim)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NfP6_8GX_gw","colab_type":"code","colab":{}},"source":["def forward(features, labels, mode):\n","    words = features['words'] if isinstance(features, dict) else features\n","    words_len = tf.count_nonzero(words, 1, dtype=tf.int32)\n","    \n","    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","    batch_sz = tf.shape(words)[0]\n","    \n","  \n","    with tf.variable_scope('Embedding'):\n","        embedding = tf.Variable(np.load('../vocab/char.npy'),\n","                                dtype=tf.float32,\n","                                name='fasttext_vectors')\n","        embedding = tf.concat([tf.zeros(shape=[1, params['embed_dim']]), embedding[1:, :]], axis=0)\n","        x = tf.nn.embedding_lookup(embedding, words)\n","        pos_embedder = tx.modules.SinusoidsPositionEmbedder(\n","            position_size = params['max_len'] + 1,\n","            hparams = config_model.position_embedder_hparams)\n","        x = (x * config_model.hidden_dim ** 0.5) + pos_embedder(sequence_length=words_len)\n","\n","\n","    with tf.variable_scope('Encoder'):\n","        encoder = TransformerEncoder(hparams=config_model.encoder)\n","        enc_out = encoder(inputs=x, sequence_length=words_len, mode=tf.estimator.ModeKeys.PREDICT)\n","        enc_state = tf.reduce_max(enc_out, axis=1)\n","        enc_state = tf.nn.rnn_cell.LSTMStateTuple(c=enc_state, h=enc_state)\n","    \n","    \n","    with tf.variable_scope('Decoder'):\n","        output_proj = TiedDense(embedding, len(params['char2idx'])+1)\n","\n","        enc_out_t = tf.contrib.seq2seq.tile_batch(enc_out, params['beam_width'])\n","        enc_state_t = tf.contrib.seq2seq.tile_batch(enc_state, params['beam_width'])\n","        enc_seq_len_t = tf.contrib.seq2seq.tile_batch(words_len, params['beam_width'])\n","        \n","        cell = dec_cell(enc_out_t, enc_seq_len_t)\n","        \n","        init_state = cell.zero_state(batch_sz*params['beam_width'], tf.float32).clone(\n","            cell_state=enc_state_t)\n","        \n","        decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n","            cell = cell,\n","            embedding = embedding,\n","            start_tokens = tf.tile(tf.constant([1], tf.int32), [batch_sz]),\n","            end_token = 2,\n","            initial_state = init_state,\n","            beam_width = params['beam_width'],\n","            output_layer = output_proj,\n","            length_penalty_weight = params['length_penalty'],)\n","        decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n","            decoder = decoder,\n","            maximum_iterations = params['max_len'],)\n","        \n","        return decoder_output.predicted_ids[:, :, :params['top_k']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYn5JxIXYXUq","colab_type":"code","colab":{}},"source":["def model_fn(features, labels, mode, params):\n","    logits_or_ids = forward(features, labels, mode)\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        return tf.estimator.EstimatorSpec(mode, predictions=logits_or_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1xX1IH0Ydb-","colab_type":"code","colab":{}},"source":["class config_model:\n","    hidden_dim = 300\n","    num_heads = 8\n","    dropout_rate = .2\n","    num_blocks = 6\n","\n","    position_embedder_hparams = {\n","        'dim': hidden_dim\n","    }\n","\n","    encoder = {\n","        'dim': hidden_dim,\n","        'embedding_dropout': dropout_rate,\n","        'residual_dropout': dropout_rate,\n","        'num_blocks': num_blocks,\n","        'initializer': {\n","            'type': 'variance_scaling_initializer',\n","            'kwargs': {\n","                'scale': 1.0,\n","                'mode': 'fan_avg',\n","                'distribution': 'uniform',\n","            },\n","        },\n","        'multihead_attention': {\n","            'dropout_rate': dropout_rate,\n","            'num_heads': num_heads,\n","            'output_dim': hidden_dim,\n","            'use_bias': True,\n","        },\n","        'poswise_feedforward': {\n","          'name': 'fnn',\n","          'layers': [\n","              {\n","                  'type': 'Dense',\n","                  'kwargs': {\n","                      'name': 'conv1',\n","                      'units': hidden_dim * 4,\n","                      'activation': 'gelu',\n","                      'use_bias': True,\n","                  },\n","              },\n","              {\n","                  'type': 'Dropout',\n","                  'kwargs': {\n","                      'rate': dropout_rate,\n","                  }\n","              },\n","              {\n","                  'type': 'Dense',\n","                  'kwargs': {\n","                      'name': 'conv2',\n","                      'units': hidden_dim,\n","                      'use_bias': True,\n","                  }\n","              }\n","          ],\n","        },\n","    }\n","\n","\n","params = {\n","    'model_dir': '../model/transformer_rnn',\n","    'export_dir': '../model/transformer_rnn_export',\n","    'vocab_path': '../vocab/char.txt',\n","    'dec_layers': 1,\n","    'rnn_units': 300,\n","    'max_len': 30,\n","    'embed_dim': config_model.hidden_dim,\n","    'beam_width': 10,\n","    'top_k': 3,\n","    'length_penalty': .0,\n","    'coverage_penalty': .0,\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfBcjT-LZAHV","colab_type":"code","colab":{}},"source":["def serving_input_receiver_fn():\n","    words = tf.placeholder(tf.int32, [None, None], 'words')\n","    features = {'words': words}\n","    receiver_tensors = features\n","    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n","\n","\n","def get_vocab(f_path):\n","  word2idx = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip('\\n')\n","      word2idx[line] = i\n","  return word2idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u8817v3ZOMT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1597653331940,"user_tz":-480,"elapsed":13558,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"77a4f32c-097d-4ee8-8769-cac64bc67cbe"},"source":["params['char2idx'] = get_vocab(params['vocab_path'])\n","params['idx2char'] = {idx: char for char, idx in params['char2idx'].items()}\n","estimator = tf.estimator.Estimator(model_fn, params['model_dir'])\n","estimator.export_saved_model(params['export_dir'], serving_input_receiver_fn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING: Entity <bound method TiedDense.call of <__main__.TiedDense object at 0x7ff5339409b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["b'../model/transformer_rnn_export/1597653320'"]},"metadata":{"tags":[]},"execution_count":10}]}]}